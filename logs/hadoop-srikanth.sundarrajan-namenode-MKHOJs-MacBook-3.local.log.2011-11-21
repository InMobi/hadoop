2011-11-21 22:22:32,953 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = MKHOJs-MacBook-3.local/192.168.0.100
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.20.2-cdh3u0
STARTUP_MSG:   build =  -r 81256ad0f2e4ab2bd34b04f53d25a6c23686dd14; compiled by 'hudson' on Fri Mar 25 19:56:23 PDT 2011
************************************************************/
2011-11-21 22:22:33,182 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=NameNode, sessionId=null
2011-11-21 22:22:33,185 INFO org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics: Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-11-21 22:22:33,214 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2011-11-21 22:22:33,214 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 19.9175 MB
2011-11-21 22:22:33,214 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2011-11-21 22:22:33,214 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2011-11-21 22:22:33,248 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=srikanth.sundarrajan
2011-11-21 22:22:33,249 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2011-11-21 22:22:33,249 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=true
2011-11-21 22:22:33,254 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=1000
2011-11-21 22:22:33,254 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2011-11-21 22:22:33,480 INFO org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMetrics: Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-11-21 22:22:33,561 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2011-11-21 22:22:33,567 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2011-11-21 22:22:33,567 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 126 loaded in 0 seconds.
2011-11-21 22:22:33,708 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Invalid opcode, reached end of edit log Number of transactions found 398
2011-11-21 22:22:33,708 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /tmp/hadoop-srikanth.sundarrajan/dfs/name/current/edits of size 1049092 edits # 398 loaded in 0 seconds.
2011-11-21 22:22:33,714 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 22634 saved in 0 seconds.
2011-11-21 22:22:33,734 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 22634 saved in 0 seconds.
2011-11-21 22:22:33,745 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 505 msecs
2011-11-21 22:22:33,754 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 96 blocks to reach the threshold 0.9990 of total blocks 97. Safe mode will be turned off automatically.
2011-11-21 22:22:33,759 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2011-11-21 22:22:33,786 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8020
2011-11-21 22:22:33,789 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=NameNode, port=8020
2011-11-21 22:22:33,790 INFO org.apache.hadoop.ipc.metrics.RpcDetailedMetrics: Initializing RPC Metrics with hostName=NameNode, port=8020
2011-11-21 22:22:33,794 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Namenode up at: localhost/127.0.0.1:8020
2011-11-21 22:22:33,844 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2011-11-21 22:22:33,972 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-11-21 22:22:33,983 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50070
2011-11-21 22:22:33,988 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50070 webServer.getConnectors()[0].getLocalPort() returned 50070
2011-11-21 22:22:33,988 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50070
2011-11-21 22:22:33,988 INFO org.mortbay.log: jetty-6.1.26
2011-11-21 22:22:34,450 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50070
2011-11-21 22:22:34,450 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Web-server up at: 0.0.0.0:50070
2011-11-21 22:22:34,450 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2011-11-21 22:22:34,451 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2011-11-21 22:22:34,452 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 8020: starting
2011-11-21 22:22:34,452 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 8020: starting
2011-11-21 22:22:34,453 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 8020: starting
2011-11-21 22:22:34,453 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 8020: starting
2011-11-21 22:22:34,453 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 8020: starting
2011-11-21 22:22:34,453 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 8020: starting
2011-11-21 22:22:34,453 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 8020: starting
2011-11-21 22:22:34,453 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 8020: starting
2011-11-21 22:22:34,453 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 8020: starting
2011-11-21 22:22:34,454 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 8020: starting
2011-11-21 22:22:34,774 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:50010 storage DS-1231794390-10.14.100.80-50010-1321874067821
2011-11-21 22:22:34,777 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2011-11-21 22:22:34,802 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 96 has reached the threshold 0.9990 of total blocks 97. Safe mode will be turned off automatically in 29 seconds.
2011-11-21 22:22:38,678 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=srikanth.sundarrajan	ip=/127.0.0.1	cmd=listStatus	src=/tmp/hadoop-srikanth.sundarrajan/mapred/system	dst=null	perm=null
2011-11-21 22:22:38,685 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 8020, call setPermission(/tmp/hadoop-srikanth.sundarrajan/mapred/system, rwx------) from 127.0.0.1:56140: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot set permission for /tmp/hadoop-srikanth.sundarrajan/mapred/system. Name node is in safe mode.
The reported blocks 97 has reached the threshold 0.9990 of total blocks 97. Safe mode will be turned off automatically in 26 seconds.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot set permission for /tmp/hadoop-srikanth.sundarrajan/mapred/system. Name node is in safe mode.
The reported blocks 97 has reached the threshold 0.9990 of total blocks 97. Safe mode will be turned off automatically in 26 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.setPermission(FSNamesystem.java:783)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.setPermission(NameNode.java:617)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:557)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1415)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1411)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1115)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1409)
2011-11-21 22:22:48,700 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=srikanth.sundarrajan	ip=/127.0.0.1	cmd=listStatus	src=/tmp/hadoop-srikanth.sundarrajan/mapred/system	dst=null	perm=null
2011-11-21 22:22:48,704 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 8020, call setPermission(/tmp/hadoop-srikanth.sundarrajan/mapred/system, rwx------) from 127.0.0.1:56141: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot set permission for /tmp/hadoop-srikanth.sundarrajan/mapred/system. Name node is in safe mode.
The reported blocks 97 has reached the threshold 0.9990 of total blocks 97. Safe mode will be turned off automatically in 16 seconds.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot set permission for /tmp/hadoop-srikanth.sundarrajan/mapred/system. Name node is in safe mode.
The reported blocks 97 has reached the threshold 0.9990 of total blocks 97. Safe mode will be turned off automatically in 16 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.setPermission(FSNamesystem.java:783)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.setPermission(NameNode.java:617)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:557)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1415)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1411)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1115)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1409)
2011-11-21 22:22:55,038 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 97 has reached the threshold 0.9990 of total blocks 97. Safe mode will be turned off automatically in 9 seconds.
2011-11-21 22:22:58,947 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=srikanth.sundarrajan	ip=/127.0.0.1	cmd=listStatus	src=/tmp/hadoop-srikanth.sundarrajan/mapred/system	dst=null	perm=null
2011-11-21 22:22:58,953 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 8020, call setPermission(/tmp/hadoop-srikanth.sundarrajan/mapred/system, rwx------) from 127.0.0.1:56142: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot set permission for /tmp/hadoop-srikanth.sundarrajan/mapred/system. Name node is in safe mode.
The reported blocks 97 has reached the threshold 0.9990 of total blocks 97. Safe mode will be turned off automatically in 5 seconds.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot set permission for /tmp/hadoop-srikanth.sundarrajan/mapred/system. Name node is in safe mode.
The reported blocks 97 has reached the threshold 0.9990 of total blocks 97. Safe mode will be turned off automatically in 5 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.setPermission(FSNamesystem.java:783)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.setPermission(NameNode.java:617)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:557)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1415)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1411)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1115)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1409)
2011-11-21 22:23:05,058 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Total number of blocks = 97
2011-11-21 22:23:05,058 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of invalid blocks = 0
2011-11-21 22:23:05,058 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of under-replicated blocks = 0
2011-11-21 22:23:05,058 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of  over-replicated blocks = 0
2011-11-21 22:23:05,058 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 31 secs.
2011-11-21 22:23:05,058 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF.
2011-11-21 22:23:05,058 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 1 datanodes
2011-11-21 22:23:05,059 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2011-11-21 22:23:08,974 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=srikanth.sundarrajan	ip=/127.0.0.1	cmd=listStatus	src=/tmp/hadoop-srikanth.sundarrajan/mapred/system	dst=null	perm=null
2011-11-21 22:23:08,979 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=srikanth.sundarrajan	ip=/127.0.0.1	cmd=setPermission	src=/tmp/hadoop-srikanth.sundarrajan/mapred/system	dst=null	perm=srikanth.sundarrajan:supergroup:rwx------
2011-11-21 22:23:08,980 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=srikanth.sundarrajan	ip=/127.0.0.1	cmd=listStatus	src=/tmp/hadoop-srikanth.sundarrajan/mapred/system	dst=null	perm=null
2011-11-21 22:23:08,982 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-809908408935058166 is added to invalidSet of 127.0.0.1:50010
2011-11-21 22:23:08,984 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=srikanth.sundarrajan	ip=/127.0.0.1	cmd=delete	src=/tmp/hadoop-srikanth.sundarrajan/mapred/system/jobtracker.info	dst=null	perm=null
2011-11-21 22:23:09,111 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=srikanth.sundarrajan	ip=/127.0.0.1	cmd=create	src=/tmp/hadoop-srikanth.sundarrajan/mapred/system/jobtracker.info	dst=null	perm=srikanth.sundarrajan:supergroup:rw-r--r--
2011-11-21 22:23:09,118 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=srikanth.sundarrajan	ip=/127.0.0.1	cmd=setPermission	src=/tmp/hadoop-srikanth.sundarrajan/mapred/system/jobtracker.info	dst=null	perm=srikanth.sundarrajan:supergroup:rw-------
2011-11-21 22:23:09,121 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /tmp/hadoop-srikanth.sundarrajan/mapred/system/jobtracker.info. blk_-8226206135919995821_1110
2011-11-21 22:23:09,187 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_-8226206135919995821_1110 size 4
2011-11-21 22:23:09,188 INFO org.apache.hadoop.hdfs.StateChange: Removing lease on  file /tmp/hadoop-srikanth.sundarrajan/mapred/system/jobtracker.info from client DFSClient_237919381
2011-11-21 22:23:09,188 INFO org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.completeFile: file /tmp/hadoop-srikanth.sundarrajan/mapred/system/jobtracker.info is closed by DFSClient_237919381
2011-11-21 22:23:09,993 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 127.0.0.1:50010 to delete  blk_-809908408935058166_1008
2011-11-21 22:23:30,161 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: readAndProcess threw exception org.apache.hadoop.security.AccessControlException: Connection from 127.0.0.1:56153 for protocol org.apache.hadoop.hdfs.protocol.ClientProtocol is unauthorized for user srikanth.sundarrajan via srikanth.sundarrajan. Count of bytes read: 0
org.apache.hadoop.security.AccessControlException: Connection from 127.0.0.1:56153 for protocol org.apache.hadoop.hdfs.protocol.ClientProtocol is unauthorized for user srikanth.sundarrajan via srikanth.sundarrajan
	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:1314)
	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:1209)
	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:566)
	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:363)
2011-11-21 22:29:44,598 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at MKHOJs-MacBook-3.local/192.168.0.100
************************************************************/
2011-11-21 22:29:49,133 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = MKHOJs-MacBook-3.local/192.168.0.100
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.20.2-cdh3u0
STARTUP_MSG:   build =  -r 81256ad0f2e4ab2bd34b04f53d25a6c23686dd14; compiled by 'hudson' on Fri Mar 25 19:56:23 PDT 2011
************************************************************/
2011-11-21 22:29:49,365 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=NameNode, sessionId=null
2011-11-21 22:29:49,368 INFO org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics: Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-11-21 22:29:49,397 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2011-11-21 22:29:49,397 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 19.9175 MB
2011-11-21 22:29:49,397 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2011-11-21 22:29:49,397 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2011-11-21 22:29:49,430 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=srikanth.sundarrajan
2011-11-21 22:29:49,430 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2011-11-21 22:29:49,430 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=true
2011-11-21 22:29:49,435 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=1000
2011-11-21 22:29:49,435 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2011-11-21 22:29:49,650 INFO org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMetrics: Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-11-21 22:29:49,694 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 149
2011-11-21 22:29:49,729 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2011-11-21 22:29:49,730 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 22634 loaded in 0 seconds.
2011-11-21 22:29:49,735 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Invalid opcode, reached end of edit log Number of transactions found 6
2011-11-21 22:29:49,735 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /tmp/hadoop-srikanth.sundarrajan/dfs/name/current/edits of size 1049092 edits # 6 loaded in 0 seconds.
2011-11-21 22:29:49,742 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 22634 saved in 0 seconds.
2011-11-21 22:29:49,801 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 22634 saved in 0 seconds.
2011-11-21 22:29:49,811 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 388 msecs
2011-11-21 22:29:49,818 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 96 blocks to reach the threshold 0.9990 of total blocks 97. Safe mode will be turned off automatically.
2011-11-21 22:29:49,824 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2011-11-21 22:29:49,850 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8020
2011-11-21 22:29:49,853 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=NameNode, port=8020
2011-11-21 22:29:49,855 INFO org.apache.hadoop.ipc.metrics.RpcDetailedMetrics: Initializing RPC Metrics with hostName=NameNode, port=8020
2011-11-21 22:29:49,858 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Namenode up at: localhost/127.0.0.1:8020
2011-11-21 22:29:49,906 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2011-11-21 22:29:49,961 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-11-21 22:29:49,970 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50070
2011-11-21 22:29:49,978 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50070 webServer.getConnectors()[0].getLocalPort() returned 50070
2011-11-21 22:29:49,978 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50070
2011-11-21 22:29:49,978 INFO org.mortbay.log: jetty-6.1.26
2011-11-21 22:29:50,402 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50070
2011-11-21 22:29:50,403 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Web-server up at: 0.0.0.0:50070
2011-11-21 22:29:50,403 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2011-11-21 22:29:50,403 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2011-11-21 22:29:50,405 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 8020: starting
2011-11-21 22:29:50,406 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 8020: starting
2011-11-21 22:29:50,406 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 8020: starting
2011-11-21 22:29:50,406 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 8020: starting
2011-11-21 22:29:50,407 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 8020: starting
2011-11-21 22:29:50,407 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 8020: starting
2011-11-21 22:29:50,407 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 8020: starting
2011-11-21 22:29:50,407 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 8020: starting
2011-11-21 22:29:50,408 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 8020: starting
2011-11-21 22:29:50,408 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 8020: starting
2011-11-21 22:29:50,430 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:50010 storage DS-1231794390-10.14.100.80-50010-1321874067821
2011-11-21 22:29:50,436 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2011-11-21 22:29:53,216 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 96 has reached the threshold 0.9990 of total blocks 97. Safe mode will be turned off automatically in 30 seconds.
2011-11-21 22:29:56,260 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=srikanth.sundarrajan	ip=/127.0.0.1	cmd=listStatus	src=/tmp/hadoop-srikanth.sundarrajan/mapred/system	dst=null	perm=null
2011-11-21 22:29:56,267 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 8020, call setPermission(/tmp/hadoop-srikanth.sundarrajan/mapred/system, rwx------) from 127.0.0.1:56241: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot set permission for /tmp/hadoop-srikanth.sundarrajan/mapred/system. Name node is in safe mode.
The reported blocks 97 has reached the threshold 0.9990 of total blocks 97. Safe mode will be turned off automatically in 26 seconds.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot set permission for /tmp/hadoop-srikanth.sundarrajan/mapred/system. Name node is in safe mode.
The reported blocks 97 has reached the threshold 0.9990 of total blocks 97. Safe mode will be turned off automatically in 26 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.setPermission(FSNamesystem.java:783)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.setPermission(NameNode.java:617)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:557)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1415)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1411)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1115)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1409)
2011-11-21 22:30:01,709 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: readAndProcess threw exception org.apache.hadoop.security.AccessControlException: Connection from 127.0.0.1:56246 for protocol org.apache.hadoop.hdfs.protocol.ClientProtocol is unauthorized for user srikanth.sundarrajan via srikanth.sundarrajan. Count of bytes read: 0
org.apache.hadoop.security.AccessControlException: Connection from 127.0.0.1:56246 for protocol org.apache.hadoop.hdfs.protocol.ClientProtocol is unauthorized for user srikanth.sundarrajan via srikanth.sundarrajan
	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:1314)
	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:1209)
	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:566)
	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:363)
2011-11-21 22:30:06,280 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=srikanth.sundarrajan	ip=/127.0.0.1	cmd=listStatus	src=/tmp/hadoop-srikanth.sundarrajan/mapred/system	dst=null	perm=null
2011-11-21 22:30:06,284 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 8020, call setPermission(/tmp/hadoop-srikanth.sundarrajan/mapred/system, rwx------) from 127.0.0.1:56248: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot set permission for /tmp/hadoop-srikanth.sundarrajan/mapred/system. Name node is in safe mode.
The reported blocks 97 has reached the threshold 0.9990 of total blocks 97. Safe mode will be turned off automatically in 16 seconds.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot set permission for /tmp/hadoop-srikanth.sundarrajan/mapred/system. Name node is in safe mode.
The reported blocks 97 has reached the threshold 0.9990 of total blocks 97. Safe mode will be turned off automatically in 16 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.setPermission(FSNamesystem.java:783)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.setPermission(NameNode.java:617)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:557)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1415)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1411)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1115)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1409)
2011-11-21 22:30:13,228 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 97 has reached the threshold 0.9990 of total blocks 97. Safe mode will be turned off automatically in 9 seconds.
2011-11-21 22:30:16,292 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=srikanth.sundarrajan	ip=/127.0.0.1	cmd=listStatus	src=/tmp/hadoop-srikanth.sundarrajan/mapred/system	dst=null	perm=null
2011-11-21 22:30:16,295 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 8020, call setPermission(/tmp/hadoop-srikanth.sundarrajan/mapred/system, rwx------) from 127.0.0.1:56250: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot set permission for /tmp/hadoop-srikanth.sundarrajan/mapred/system. Name node is in safe mode.
The reported blocks 97 has reached the threshold 0.9990 of total blocks 97. Safe mode will be turned off automatically in 6 seconds.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot set permission for /tmp/hadoop-srikanth.sundarrajan/mapred/system. Name node is in safe mode.
The reported blocks 97 has reached the threshold 0.9990 of total blocks 97. Safe mode will be turned off automatically in 6 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.setPermission(FSNamesystem.java:783)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.setPermission(NameNode.java:617)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:557)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1415)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1411)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1115)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1409)
2011-11-21 22:30:23,241 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Total number of blocks = 97
2011-11-21 22:30:23,241 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of invalid blocks = 0
2011-11-21 22:30:23,241 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of under-replicated blocks = 0
2011-11-21 22:30:23,241 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of  over-replicated blocks = 0
2011-11-21 22:30:23,241 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 33 secs.
2011-11-21 22:30:23,241 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF.
2011-11-21 22:30:23,241 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 1 datanodes
2011-11-21 22:30:23,241 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2011-11-21 22:30:26,303 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=srikanth.sundarrajan	ip=/127.0.0.1	cmd=listStatus	src=/tmp/hadoop-srikanth.sundarrajan/mapred/system	dst=null	perm=null
2011-11-21 22:30:26,308 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=srikanth.sundarrajan	ip=/127.0.0.1	cmd=setPermission	src=/tmp/hadoop-srikanth.sundarrajan/mapred/system	dst=null	perm=srikanth.sundarrajan:supergroup:rwx------
2011-11-21 22:30:26,310 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=srikanth.sundarrajan	ip=/127.0.0.1	cmd=listStatus	src=/tmp/hadoop-srikanth.sundarrajan/mapred/system	dst=null	perm=null
2011-11-21 22:30:26,314 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-8226206135919995821 is added to invalidSet of 127.0.0.1:50010
2011-11-21 22:30:26,316 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=srikanth.sundarrajan	ip=/127.0.0.1	cmd=delete	src=/tmp/hadoop-srikanth.sundarrajan/mapred/system/jobtracker.info	dst=null	perm=null
2011-11-21 22:30:26,481 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=srikanth.sundarrajan	ip=/127.0.0.1	cmd=create	src=/tmp/hadoop-srikanth.sundarrajan/mapred/system/jobtracker.info	dst=null	perm=srikanth.sundarrajan:supergroup:rw-r--r--
2011-11-21 22:30:26,499 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=srikanth.sundarrajan	ip=/127.0.0.1	cmd=setPermission	src=/tmp/hadoop-srikanth.sundarrajan/mapred/system/jobtracker.info	dst=null	perm=srikanth.sundarrajan:supergroup:rw-------
2011-11-21 22:30:26,502 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /tmp/hadoop-srikanth.sundarrajan/mapred/system/jobtracker.info. blk_8152673234593069612_1111
2011-11-21 22:30:26,613 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_8152673234593069612_1111 size 4
2011-11-21 22:30:26,614 INFO org.apache.hadoop.hdfs.StateChange: Removing lease on  file /tmp/hadoop-srikanth.sundarrajan/mapred/system/jobtracker.info from client DFSClient_-2122377047
2011-11-21 22:30:26,615 INFO org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.completeFile: file /tmp/hadoop-srikanth.sundarrajan/mapred/system/jobtracker.info is closed by DFSClient_-2122377047
2011-11-21 22:30:28,827 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 127.0.0.1:50010 to delete  blk_-8226206135919995821_1110
2011-11-21 22:34:42,304 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at MKHOJs-MacBook-3.local/192.168.0.100
************************************************************/
2011-11-21 22:34:49,862 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = MKHOJs-MacBook-3.local/192.168.0.100
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.20.2-cdh3u0
STARTUP_MSG:   build =  -r 81256ad0f2e4ab2bd34b04f53d25a6c23686dd14; compiled by 'hudson' on Fri Mar 25 19:56:23 PDT 2011
************************************************************/
2011-11-21 22:34:50,103 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=NameNode, sessionId=null
2011-11-21 22:34:50,106 INFO org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics: Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-11-21 22:34:50,135 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2011-11-21 22:34:50,135 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 19.9175 MB
2011-11-21 22:34:50,135 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2011-11-21 22:34:50,135 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2011-11-21 22:34:50,172 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=srikanth.sundarrajan
2011-11-21 22:34:50,172 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2011-11-21 22:34:50,173 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=true
2011-11-21 22:34:50,178 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=1000
2011-11-21 22:34:50,178 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2011-11-21 22:34:50,424 INFO org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMetrics: Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-11-21 22:34:50,472 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 149
2011-11-21 22:34:50,509 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2011-11-21 22:34:50,510 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 22634 loaded in 0 seconds.
2011-11-21 22:34:50,516 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Invalid opcode, reached end of edit log Number of transactions found 6
2011-11-21 22:34:50,516 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /tmp/hadoop-srikanth.sundarrajan/dfs/name/current/edits of size 1049092 edits # 6 loaded in 0 seconds.
2011-11-21 22:34:50,524 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 22634 saved in 0 seconds.
2011-11-21 22:34:50,583 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 22634 saved in 0 seconds.
2011-11-21 22:34:50,594 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 430 msecs
2011-11-21 22:34:50,606 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 96 blocks to reach the threshold 0.9990 of total blocks 97. Safe mode will be turned off automatically.
2011-11-21 22:34:50,611 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2011-11-21 22:34:50,637 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8020
2011-11-21 22:34:50,640 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=NameNode, port=8020
2011-11-21 22:34:50,645 INFO org.apache.hadoop.ipc.metrics.RpcDetailedMetrics: Initializing RPC Metrics with hostName=NameNode, port=8020
2011-11-21 22:34:50,648 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Namenode up at: localhost/127.0.0.1:8020
2011-11-21 22:34:50,698 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2011-11-21 22:34:50,752 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-11-21 22:34:50,764 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50070
2011-11-21 22:34:50,769 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50070 webServer.getConnectors()[0].getLocalPort() returned 50070
2011-11-21 22:34:50,769 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50070
2011-11-21 22:34:50,769 INFO org.mortbay.log: jetty-6.1.26
2011-11-21 22:34:51,216 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50070
2011-11-21 22:34:51,216 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Web-server up at: 0.0.0.0:50070
2011-11-21 22:34:51,216 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2011-11-21 22:34:51,217 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2011-11-21 22:34:51,218 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 8020: starting
2011-11-21 22:34:51,218 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 8020: starting
2011-11-21 22:34:51,218 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 8020: starting
2011-11-21 22:34:51,218 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 8020: starting
2011-11-21 22:34:51,219 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 8020: starting
2011-11-21 22:34:51,219 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 8020: starting
2011-11-21 22:34:51,219 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 8020: starting
2011-11-21 22:34:51,219 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 8020: starting
2011-11-21 22:34:51,219 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 8020: starting
2011-11-21 22:34:51,219 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 8020: starting
2011-11-21 22:34:51,334 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:50010 storage DS-1231794390-10.14.100.80-50010-1321874067821
2011-11-21 22:34:51,337 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2011-11-21 22:34:51,359 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 96 has reached the threshold 0.9990 of total blocks 97. Safe mode will be turned off automatically in 29 seconds.
2011-11-21 22:35:00,756 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=srikanth.sundarrajan	ip=/127.0.0.1	cmd=listStatus	src=/tmp/hadoop-srikanth.sundarrajan/mapred/system	dst=null	perm=null
2011-11-21 22:35:00,763 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 8020, call setPermission(/tmp/hadoop-srikanth.sundarrajan/mapred/system, rwx------) from 127.0.0.1:56304: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot set permission for /tmp/hadoop-srikanth.sundarrajan/mapred/system. Name node is in safe mode.
The reported blocks 97 has reached the threshold 0.9990 of total blocks 97. Safe mode will be turned off automatically in 20 seconds.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot set permission for /tmp/hadoop-srikanth.sundarrajan/mapred/system. Name node is in safe mode.
The reported blocks 97 has reached the threshold 0.9990 of total blocks 97. Safe mode will be turned off automatically in 20 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.setPermission(FSNamesystem.java:783)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.setPermission(NameNode.java:617)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:557)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1415)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1411)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1115)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1409)
2011-11-21 22:35:10,776 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=srikanth.sundarrajan	ip=/127.0.0.1	cmd=listStatus	src=/tmp/hadoop-srikanth.sundarrajan/mapred/system	dst=null	perm=null
2011-11-21 22:35:10,781 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 8020, call setPermission(/tmp/hadoop-srikanth.sundarrajan/mapred/system, rwx------) from 127.0.0.1:56305: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot set permission for /tmp/hadoop-srikanth.sundarrajan/mapred/system. Name node is in safe mode.
The reported blocks 97 has reached the threshold 0.9990 of total blocks 97. Safe mode will be turned off automatically in 10 seconds.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot set permission for /tmp/hadoop-srikanth.sundarrajan/mapred/system. Name node is in safe mode.
The reported blocks 97 has reached the threshold 0.9990 of total blocks 97. Safe mode will be turned off automatically in 10 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.setPermission(FSNamesystem.java:783)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.setPermission(NameNode.java:617)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:557)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1415)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1411)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1115)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1409)
2011-11-21 22:35:11,370 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 97 has reached the threshold 0.9990 of total blocks 97. Safe mode will be turned off automatically in 9 seconds.
2011-11-21 22:35:20,789 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=srikanth.sundarrajan	ip=/127.0.0.1	cmd=listStatus	src=/tmp/hadoop-srikanth.sundarrajan/mapred/system	dst=null	perm=null
2011-11-21 22:35:20,792 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 8020, call setPermission(/tmp/hadoop-srikanth.sundarrajan/mapred/system, rwx------) from 127.0.0.1:56308: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot set permission for /tmp/hadoop-srikanth.sundarrajan/mapred/system. Name node is in safe mode.
The reported blocks 97 has reached the threshold 0.9990 of total blocks 97. Safe mode will be turned off automatically in 0 seconds.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot set permission for /tmp/hadoop-srikanth.sundarrajan/mapred/system. Name node is in safe mode.
The reported blocks 97 has reached the threshold 0.9990 of total blocks 97. Safe mode will be turned off automatically in 0 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.setPermission(FSNamesystem.java:783)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.setPermission(NameNode.java:617)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:557)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1415)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1411)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1115)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1409)
2011-11-21 22:35:21,414 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Total number of blocks = 97
2011-11-21 22:35:21,414 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of invalid blocks = 0
2011-11-21 22:35:21,414 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of under-replicated blocks = 0
2011-11-21 22:35:21,414 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of  over-replicated blocks = 0
2011-11-21 22:35:21,414 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 31 secs.
2011-11-21 22:35:21,414 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF.
2011-11-21 22:35:21,415 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 1 datanodes
2011-11-21 22:35:21,415 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2011-11-21 22:35:30,801 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=srikanth.sundarrajan	ip=/127.0.0.1	cmd=listStatus	src=/tmp/hadoop-srikanth.sundarrajan/mapred/system	dst=null	perm=null
2011-11-21 22:35:30,805 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=srikanth.sundarrajan	ip=/127.0.0.1	cmd=setPermission	src=/tmp/hadoop-srikanth.sundarrajan/mapred/system	dst=null	perm=srikanth.sundarrajan:supergroup:rwx------
2011-11-21 22:35:30,807 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=srikanth.sundarrajan	ip=/127.0.0.1	cmd=listStatus	src=/tmp/hadoop-srikanth.sundarrajan/mapred/system	dst=null	perm=null
2011-11-21 22:35:30,809 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_8152673234593069612 is added to invalidSet of 127.0.0.1:50010
2011-11-21 22:35:30,810 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=srikanth.sundarrajan	ip=/127.0.0.1	cmd=delete	src=/tmp/hadoop-srikanth.sundarrajan/mapred/system/jobtracker.info	dst=null	perm=null
2011-11-21 22:35:30,908 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=srikanth.sundarrajan	ip=/127.0.0.1	cmd=create	src=/tmp/hadoop-srikanth.sundarrajan/mapred/system/jobtracker.info	dst=null	perm=srikanth.sundarrajan:supergroup:rw-r--r--
2011-11-21 22:35:30,916 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=srikanth.sundarrajan	ip=/127.0.0.1	cmd=setPermission	src=/tmp/hadoop-srikanth.sundarrajan/mapred/system/jobtracker.info	dst=null	perm=srikanth.sundarrajan:supergroup:rw-------
2011-11-21 22:35:30,919 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /tmp/hadoop-srikanth.sundarrajan/mapred/system/jobtracker.info. blk_5226956801338502813_1112
2011-11-21 22:35:30,986 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_5226956801338502813_1112 size 4
2011-11-21 22:35:31,388 INFO org.apache.hadoop.hdfs.StateChange: Removing lease on  file /tmp/hadoop-srikanth.sundarrajan/mapred/system/jobtracker.info from client DFSClient_474036876
2011-11-21 22:35:31,388 INFO org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.completeFile: file /tmp/hadoop-srikanth.sundarrajan/mapred/system/jobtracker.info is closed by DFSClient_474036876
2011-11-21 22:35:32,611 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 127.0.0.1:50010 to delete  blk_8152673234593069612_1111
2011-11-21 22:35:55,060 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: readAndProcess threw exception org.apache.hadoop.security.AccessControlException: Connection from 127.0.0.1:56317 for protocol org.apache.hadoop.hdfs.protocol.ClientProtocol is unauthorized for user srikanth.sundarrajan via srikanth.sundarrajan. Count of bytes read: 0
org.apache.hadoop.security.AccessControlException: Connection from 127.0.0.1:56317 for protocol org.apache.hadoop.hdfs.protocol.ClientProtocol is unauthorized for user srikanth.sundarrajan via srikanth.sundarrajan
	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:1314)
	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:1209)
	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:566)
	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:363)
